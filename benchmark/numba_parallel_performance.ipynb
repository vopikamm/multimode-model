{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as t\n",
    "import numba as nb\n",
    "from multimodemodel import _cyclic_shift\n",
    "import numba.core.runtime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(inline='always')  # type: ignore\n",
    "def _advection_momentum_u(\n",
    "    i: int, j: int, k: int,\n",
    "    m: int, n: int,\n",
    "    ni: int, nj: int, nk: int,\n",
    "    lbc: int,\n",
    "    u: np.ndarray, v: np.ndarray, w: np.ndarray,\n",
    "    mask_u: np.ndarray, mask_v: np.ndarray, mask_q: np.ndarray,\n",
    "    dx_u: np.ndarray, dy_u: np.ndarray, dx_v: np.ndarray,\n",
    "    ppp: np.ndarray, ppw: np.ndarray,\n",
    ") -> float:  # pragma: no cover\n",
    "    \"\"\"Compute the advection of zonal momentum.\"\"\"\n",
    "    if mask_u[k, j, i] == 0:\n",
    "        return 0.\n",
    "\n",
    "    ip1 = _cyclic_shift(i, ni, 1)\n",
    "    im1 = _cyclic_shift(i, ni, -1)\n",
    "    jp1 = _cyclic_shift(j, nj, 1)\n",
    "    jm1 = _cyclic_shift(j, nj, -1)\n",
    "\n",
    "    if mask_q[k, j, i] == 0:\n",
    "        lbc = lbc\n",
    "    else:\n",
    "        lbc = 1\n",
    "\n",
    "    return (\n",
    "        ppp[n, m, k]\n",
    "        * mask_u[k, j, i]\n",
    "        * (\n",
    "            (\n",
    "                dy_u[j, ip1] * mask_u[n, j, ip1] * u[n, j, ip1]\n",
    "                + dy_u[j, i] * mask_u[n, j, i] * u[n, j, i]\n",
    "            )\n",
    "            * (mask_u[m, j, ip1] * u[m, j, ip1] + mask_u[m, j, i] * u[m, j, i])\n",
    "            - (\n",
    "                dy_u[j, i] * mask_u[n, j, i] * u[n, j, i]\n",
    "                + dy_u[j, im1] * mask_u[n, j, im1] * u[n, j, im1]\n",
    "            )\n",
    "            * (mask_u[m, j, i] * u[m, j, i] + mask_u[m, j, im1] * u[m, j, im1])\n",
    "            + (\n",
    "                dx_v[jp1, i] * mask_v[n, jp1, i] * v[n, jp1, i]\n",
    "                + dx_v[jp1, im1] * mask_v[n, jp1, im1] * v[n, jp1, im1]\n",
    "            )\n",
    "            * (mask_u[m, jp1, i] * u[m, jp1, i] + mask_u[m, j, i] * u[m, j, i])\n",
    "            - (\n",
    "                dx_v[j, i] * mask_v[n, j, i] * v[n, j, i]\n",
    "                + dx_v[j, im1] * mask_v[n, j, im1] * v[n, j, im1]\n",
    "            )\n",
    "            * (lbc * mask_u[m, j, i] * u[m, j, i] + mask_u[m, jm1, i] * u[m, jm1, i])\n",
    "        )\n",
    "        / dx_u[j, i]\n",
    "        / dy_u[j, i]\n",
    "        / 4\n",
    "        + ppw[n, m, k] * mask_u[k, j, i] * u[m, j, i] * (w[n, j, i] + w[n, j, im1]) / 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(inline='always')  # type: ignore\n",
    "def _advection_momentum_u_alt(\n",
    "    i: int,\n",
    "    j: int,\n",
    "    k: int,\n",
    "    ni: int,\n",
    "    nj: int,\n",
    "    nk: int,\n",
    "    lbc: int,\n",
    "    u: np.ndarray,\n",
    "    v: np.ndarray,\n",
    "    w: np.ndarray,\n",
    "    mask_u: np.ndarray,\n",
    "    mask_v: np.ndarray,\n",
    "    mask_q: np.ndarray,\n",
    "    dx_u: np.ndarray,\n",
    "    dy_u: np.ndarray,\n",
    "    dx_v: np.ndarray,\n",
    "    ppp: np.ndarray,\n",
    "    ppw: np.ndarray,\n",
    ") -> float:  # pragma: no cover\n",
    "    \"\"\"Compute the advection of zonal momentum.\"\"\"\n",
    "    if mask_u[k, j, i] == 0:\n",
    "        return 0.\n",
    "\n",
    "    ip1 = _cyclic_shift(i, ni, 1)\n",
    "    im1 = _cyclic_shift(i, ni, -1)\n",
    "    jp1 = _cyclic_shift(j, nj, 1)\n",
    "    jm1 = _cyclic_shift(j, nj, -1)\n",
    "    \n",
    "    if mask_q[k, j, i] == 0:\n",
    "        lbc = lbc\n",
    "    else:\n",
    "        lbc = 1\n",
    "\n",
    "    mask_fac_ppp = mask_u[k, j, i] / dx_u[j, i] / dy_u[j, i] / 4\n",
    "    mask_fac_ppw = 0.5 * mask_u[k, j, i]\n",
    "\n",
    "    result = 0.\n",
    "    \n",
    "    for n in range(nk):\n",
    "        u_eta_n_ij = (\n",
    "            dy_u[j, ip1] * mask_u[n, j, ip1] * u[n, j, ip1]\n",
    "            + dy_u[j, i] * mask_u[n, j, i] * u[n, j, i]\n",
    "        )\n",
    "        u_eta_n_im1j = (\n",
    "            dy_u[j, i] * mask_u[n, j, i] * u[n, j, i]\n",
    "            + dy_u[j, im1] * mask_u[n, j, im1] * u[n, j, im1]\n",
    "        )\n",
    "        v_q_n_ijp1 = (\n",
    "            dx_v[jp1, i] * mask_v[n, jp1, i] * v[n, jp1, i]\n",
    "            + dx_v[jp1, im1] * mask_v[n, jp1, im1] * v[n, jp1, im1]\n",
    "        )\n",
    "        v_q_n_ij = (\n",
    "            dx_v[j, i] * mask_v[n, j, i] * v[n, j, i]\n",
    "            + dx_v[j, im1] * mask_v[n, j, im1] * v[n, j, im1]\n",
    "        )\n",
    "        w_u_n_ij = w[n, j, i] + w[n, j, im1]\n",
    "\n",
    "        for m in range(nk):\n",
    "            result += (\n",
    "                ppp[n, m, k]\n",
    "                * mask_fac_ppp\n",
    "                * (\n",
    "                    u_eta_n_ij\n",
    "                    * (mask_u[m, j, ip1] * u[m, j, ip1] + mask_u[m, j, i] * u[m, j, i])\n",
    "                    - u_eta_n_im1j\n",
    "                    * (mask_u[m, j, i] * u[m, j, i] + mask_u[m, j, im1] * u[m, j, im1])\n",
    "                    + v_q_n_ijp1\n",
    "                    * (mask_u[m, jp1, i] * u[m, jp1, i] + mask_u[m, j, i] * u[m, j, i])\n",
    "                    - v_q_n_ij\n",
    "                    * (lbc * mask_u[m, j, i] * u[m, j, i] + mask_u[m, jm1, i] * u[m, jm1, i])\n",
    "                )\n",
    "                + ppw[n, m, k] * mask_fac_ppw * u[m, j, i] * w_u_n_ij\n",
    "            )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)  # type: ignore\n",
    "def _numba_double_sum_parallel_over_nm_preallocated(args):\n",
    "    ni, nj, nk = args[0], args[1], args[2]\n",
    "    result = np.empty((nk * nk, nk, nj, ni))\n",
    "    for ind in nb.prange(nk * nk):\n",
    "        n, m = divmod(ind, nk)\n",
    "        n = int(n)\n",
    "        m = int(m)\n",
    "        for k in range(nk):\n",
    "            for j in range(nj):\n",
    "                for i in range(ni):\n",
    "                    result[ind, k, j, i] = _advection_momentum_u(\n",
    "                        i, j, k,\n",
    "                        m, n,\n",
    "                        ni, nj, nk,\n",
    "                        args[3],\n",
    "                        args[4], args[5], args[6],\n",
    "                        args[7], args[8], args[9],\n",
    "                        args[10], args[11], args[12],\n",
    "                        args[13], args[14],\n",
    "                    )\n",
    "    \n",
    "    return result.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)  # type: ignore\n",
    "def _numba_double_sum_parallel_over_nmk(args):\n",
    "    n_threads = nb.get_num_threads()\n",
    "    ni, nj, nk = args[0], args[1], args[2]\n",
    "    result = np.zeros((n_threads, nk, nj, ni))\n",
    "    for ind in nb.prange(nk * nk * nk):\n",
    "        tid = nb.np.ufunc.parallel._get_thread_id()\n",
    "        n, residual = divmod(ind, nk * nk)\n",
    "        m, k = divmod(residual, nk)\n",
    "        n = int(n)\n",
    "        m = int(m)\n",
    "        k = int(k)\n",
    "        for j in range(nj):\n",
    "            for i in range(ni):\n",
    "                result[tid, k, j, i] += _advection_momentum_u(\n",
    "                    i, j, k,\n",
    "                    m, n,\n",
    "                    ni, nj, nk,\n",
    "                    args[3],\n",
    "                    args[4], args[5], args[6],\n",
    "                    args[7], args[8], args[9],\n",
    "                    args[10], args[11], args[12],\n",
    "                    args[13], args[14],\n",
    "                )\n",
    "    return result.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)  # type: ignore\n",
    "def _numba_double_sum_parallel_over_k(args):\n",
    "    ni, nj, nk = args[0], args[1], args[2]\n",
    "    result = np.zeros((nk, nj, ni))\n",
    "    for k in nb.prange(nk):\n",
    "        for n in range(nk):\n",
    "            for m in range(nk):\n",
    "                for j in range(nj):\n",
    "                    for i in range(ni):\n",
    "                        result[k, j, i] += _advection_momentum_u(\n",
    "                        i, j, k,\n",
    "                        m, n,\n",
    "                        ni, nj, nk,\n",
    "                        args[3],\n",
    "                        args[4], args[5], args[6],\n",
    "                        args[7], args[8], args[9],\n",
    "                        args[10], args[11], args[12],\n",
    "                        args[13], args[14],\n",
    "                        )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)  # type: ignore\n",
    "def _numba_double_sum_parallel_over_kji(args):\n",
    "    ni, nj, nk = args[0], args[1], args[2]\n",
    "    result = np.zeros((nk, nj, ni))\n",
    "    for ind in nb.prange(nk * nj * ni):\n",
    "        k, residual = divmod(ind, nj * ni)\n",
    "        j, i = divmod(residual, ni)\n",
    "        k = int(k)\n",
    "        j = int(j)\n",
    "        i = int(i)\n",
    "        for m in range(nk):\n",
    "            for n in range(nk):\n",
    "                result[k, j, i] += _advection_momentum_u(\n",
    "                    i, j, k,\n",
    "                    m, n,\n",
    "                    ni, nj, nk,\n",
    "                    args[3],\n",
    "                    args[4], args[5], args[6],\n",
    "                    args[7], args[8], args[9],\n",
    "                    args[10], args[11], args[12],\n",
    "                    args[13], args[14],\n",
    "                )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit(parallel=True)  # type: ignore\n",
    "def _numba_double_sum_parallel_over_kji_alt(args):\n",
    "    ni, nj, nk = args[0], args[1], args[2]\n",
    "    result = np.empty((nk, nj, ni))\n",
    "    for ind in nb.prange(nk * nj * ni):\n",
    "        k, residual = divmod(ind, nj * ni)\n",
    "        j, i = divmod(residual, ni)\n",
    "        k = int(k)\n",
    "        j = int(j)\n",
    "        i = int(i)\n",
    "        result[k, j, i] = _advection_momentum_u_alt(\n",
    "            i, j, k,\n",
    "            ni, nj, nk,\n",
    "            args[3],\n",
    "            args[4], args[5], args[6],\n",
    "            args[7], args[8], args[9],\n",
    "            args[10], args[11], args[12],\n",
    "            args[13], args[14],\n",
    "        )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nk, nj, ni = 16, 41, 41\n",
    "\n",
    "args = (\n",
    "    ni, nj, nk,\n",
    "    0,\n",
    "    np.random.randn(nk, nj, ni),\n",
    "    np.random.randn(nk, nj, ni),\n",
    "    np.random.randn(nk, nj, ni),\n",
    "    np.random.choice([0, 1], (nk, nj, ni)),\n",
    "    np.random.choice([0, 1], (nk, nj, ni)),\n",
    "    np.random.choice([0, 1], (nk, nj, ni)),\n",
    "    np.ones((nj, ni)),\n",
    "    np.ones((nj, ni)),\n",
    "    np.random.randn(nj, ni),\n",
    "    np.ones((nk, nk, nk)),\n",
    "    np.ones((nk, nk, nk)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocation_difference(func, args):\n",
    "   a = rt.rtsys.get_allocation_stats().alloc - rt.rtsys.get_allocation_stats().free\n",
    "   if type(func)==np.ufunc:\n",
    "      func(*args)\n",
    "   else:\n",
    "      func(args)\n",
    "   b =  rt.rtsys.get_allocation_stats().alloc - rt.rtsys.get_allocation_stats().free\n",
    "   return b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocation_difference(_numba_double_sum_parallel_over_k, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocation_difference(_numba_double_sum_parallel_over_kji, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocation_difference(_numba_double_sum_parallel_over_kji_alt, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocation_difference(_numba_double_sum_parallel_over_nmk, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allocation_difference(_numba_double_sum_parallel_over_nm_preallocated, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 ms ± 7.47 ms per loop (mean ± std. dev. of 20 runs, 20 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 21 ms ± 7.47 ms per loop (mean ± std. dev. of 20 runs, 20 loops each)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -n20 -r20 -o \n",
    "_numba_double_sum_parallel_over_k(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.1 ms ± 1.45 ms per loop (mean ± std. dev. of 20 runs, 20 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 18.1 ms ± 1.45 ms per loop (mean ± std. dev. of 20 runs, 20 loops each)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -n20 -r20 -o \n",
    "_numba_double_sum_parallel_over_kji(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.46 ms ± 731 µs per loop (mean ± std. dev. of 20 runs, 20 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 5.46 ms ± 731 µs per loop (mean ± std. dev. of 20 runs, 20 loops each)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -n20 -r20 -o \n",
    "_numba_double_sum_parallel_over_kji_alt(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.6 ms ± 1.22 ms per loop (mean ± std. dev. of 20 runs, 20 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 20.6 ms ± 1.22 ms per loop (mean ± std. dev. of 20 runs, 20 loops each)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -n20 -r20 -o \n",
    "_numba_double_sum_parallel_over_nmk(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.7 ms ± 2.45 ms per loop (mean ± std. dev. of 20 runs, 20 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 40.7 ms ± 2.45 ms per loop (mean ± std. dev. of 20 runs, 20 loops each)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%timeit -n20 -r20 -o \n",
    "_numba_double_sum_parallel_over_nm_preallocated(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threading layer chosen: omp\n"
     ]
    }
   ],
   "source": [
    "print(\"Threading layer chosen: %s\" % nb.threading_layer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = _numba_double_sum_parallel_over_nm_preallocated(args)\n",
    "\n",
    "assert np.allclose(_numba_double_sum_parallel_over_k(args), oracle)\n",
    "assert np.allclose(_numba_double_sum_parallel_over_kji(args), oracle)\n",
    "assert np.allclose(_numba_double_sum_parallel_over_kji_alt(args), oracle)\n",
    "assert np.allclose(_numba_double_sum_parallel_over_nmk(args), oracle)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
